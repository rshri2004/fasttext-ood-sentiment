# How does incorporating synthetic movie review data influence the performance of a lightweight, scalable FastText-based sentiment classification pipeline for out-of-distribution reviews

### Overview
This project examines the impact of synthetic data and submodular data selection on sentiment classification performance using a FastText model.

### Our Motivation
Sentiment classification is a core task in natural language processing (NLP), where models determine whether a given piece of text expresses a positive or negative tone. As large language models (LLMs) have become widespread, synthetic text generated by AI is increasingly mixed into the data available online. Since many NLP models are trained on internet-scale corpora, modern models inevitably learn from a combination of human-written and LLM-generated content.

#### Our Questions:
1. Can synthetically generated data effectively replace real data in sentiment classification?
2. Can submodular data selection preserve or improve performance by selecting more informative subsets?

### Our Goal
Our goal is to understand
- How synthetic data affects model accuracy
- Whether submodular selection improves dataset quality
- How well models generalize to unseen domains(OOD)

### Our Approach
This project combines both ideas—synthetic data generation and submodular data selection—using a FastText sentiment classifier.
1. Preprocess IMDB Review dataset
2. Generate a Synthetic dataset
3. Apply submodular selection to filter more diverse subsets
4. Evaluate performance on two domains
   - IMDB test set → In-distribution
   - Amazon Reviews test set → Out-of-distribution (OOD) 
    #### Our Ablation Studies
         1. Impact of the Data Source
         2. Impact of Submodular Data Selection 
  

